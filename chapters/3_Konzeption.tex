\chapter{Konzeption}
In diesem Kapitel werde ich die grundlegende Konzeption der Arbeit vorstellen.

\section{Methodisches Vorgehen}
Es soll eine Beispielanwendung sowohl Containerisiert als auch Serverless entwickelt werden. Im Anschluss werden Performance Tests gegen beide Anwendungen durchgeführt und die Ergebnisse miteinander verglichen.

\section{AWS Lambda}
Die Serverless Anwendung soll auf AWS Lambda ausgeführt werden. Dabei handelt es sich um ein Function-as-a-service Angebot von Amazon AWS.

\subsection{Funktionsweise}
Die Funktionsweise von Lambda lässt sich wie folgt beschreiben\cite{amazon_aws_aws_2020}:

\begin{enumerate}
\item Es tritt ein Event ein, dass die Ausführung der Lambda-Funktion anfordert. \\
    Dabei kann es sich um alle mögliche Ereignisse handeln. Zum Beispiel ein Dateiupload in S3 (AWS Object Store), einen CRON-Job oder im Falle eines Web Backends eine API-Aufruf mittels AWS API-Gateway.

\item Init Phase: Lambda erstellt automatisch eine Ausführungsumgebung (environment). \\
    Dabei handelt es sich um eine isolierte Umgebung, die für die Ausführung der Lambda- Funktion benötigt wird. Für diese Umgebung lassen sich einige Parameter von Anwender konfigurieren:
    
    \begin{enumerate}
        \item Die Runtime: Dabei handelt es sich um die verwendete Programmiersprache bzw. Framework. Als Optionen bietet Lambda beispielsweise Node.js 12.x, Java, Python oder Go.
        \item Die Arbeitsspeichergröße: Wie viel Speicher der ausgeführten Funktion bereitsteht. Die Mindestgröße beträgt hier 128MB; maximal sind etwas mehr als 10GB möglich. Proportional zur Speichergröße bestimmt Lambda ebenfalls die CPU Leistung, mit der die Funktion ausgeführt wird.
        \item Timeout: Die maximale Ausführungszeit der Funktion bevor Lambda sie automatisch beendet. Hier sind maximal 15 Minuten möglich.
    \end{enumerate}
    
    Die Umgebung wird mit den konfigurierten Ressourcen (Speicher, CPU) erstellt, der Code der Funktion geladen und entpackt und der Initialisierungscode der Lambda Funktion (nicht die Funktion an sich) ausgeführt. Dort lässt sich bspw. eine Datenbankverbindung aufbauen.
    
\item Invoke Phase: In dieser Phase wird die eigentliche Lambda Funktion, welche auch als Handler bezeichnet wird, ausgeführt. Eventuelle Rückgabewerte werden an den Aufrufer zurückgeliefert. Nachdem der Handler ausgeführt wurde, bleibt er verfügbar für weitere Anfragen. Der Initialisierungscode wird allerdings nicht mehr ausgeführt.
    
\item Shutdown Phase: Nachdem die Funktion für einige Zeit nicht mehr angefragt wurde, wird die Ausführungsumgebung wieder freigegeben. 
\end{enumerate}

\subsection{Cold- und Warmstart}
Nachdem der Handler in der Invoke-Phase ausgeführt wurde, wird die Ausführungsumgebung nicht sofort wieder freigegeben, sondern für einige Zeit vorgehalten, um weitere Anfragen schneller zu bearbeiten. Dies wird auch als Warmstart bezeichnet, da die Runtime-Umgebung bereits initialisiert ist und der Handler sofort aktiviert werden kann.
Muss die Umgebung nach einer eingetroffenen Anfrage erst noch initialisiert werden, also erst die Init-Phase ausgeführt werden, wird dies als Coldstart bezeichnet. Aufgrund des Mehraufwandes, erweist sich ein Coldstart als deutlich langsamer als ein Warmstart.

\subsection{Nebenläufigkeit}
Befindet sich der Handler einer Lambda-Funktion gerade in der Ausführung und es trifft ein weiteres Ereignis ein, startet Lambda zusätzlich zu der bereits laufenden Funktion eine weitere Ausführungsumgebung, um diese neue Anfrage zu verarbeiten. Da nun mehrere Umgebungen gleichzeitig ausgeführt werden, wird dies auch als Nebenläufigkeit (engl. concurrency) bezeichnet. Bei vielen gleichzeitigen Anfragen werden also so viele Umgebungen wie nötig erstellt. Der AWS Lambda Service erlaubt standardmäßig 1000 nebenläufige Funktionen pro AWS Region, dieser Wert lässt sich allerdings nach Absprache mit AWS erhöhen.

Durch die Nebenläufigkeit wird die Stärke von Lambda Funktionen bei der Skalierung deutlich. Gibt es einen Anfragesturm, werden automatisch neue Instanzen aufgesetzt, die diese Bearbeiten können. Bereits initialisierte Umgebungen werden wiederverwendet. Lässt die Anfrage nach, werden Umgebungen automatisch wieder heruntergefahren. 

Allerdings muss für jede neue Umgebung ist ein Coldstart durchgeführt werden der viel Zeit kostet und sich dem Benutzer als deutliche Latenz bemerkbar macht. Und auch für die Ausführungskosten stellen Coldstarts ein Problem dar, denn Lambda-Funktionen werden nach der Ausführungszeit in Millisekunden abgerechnet. Darum gilt es, Coldstarts möglichst zu vermeiden. Beispielsweise lassen sich mit Provisioned Concurrency bereits Funktionen vor-starten, die dann bei Bedarf nicht mehr einen Kaltstart erfordern. Kombiniert mit Autoscaling, das die provisionierte Kapazität an steigende Anfragezahlen anpasst, lässt sich so die Anzahl an Kaltstarts vermindern.

\subsection{Kosten}
Wie bereits erwähnt, wird die Ausführung von Lambda-Funktionen nach der Ausführungszeit in Millisekunden abgerechnet. Dabei zählt die Zeit eines Cold-Starts mit in die Berechnung ein. Bei der Berechnung zählt aber auch die konfigurierte Arbeitsspeichergröße mit in das Ergebnis ein. Derzeit berechnet AWS in der Region Frankfurt (eu-central-1) Kosten von 0,0000166667 US-Dollar pro GB-Sekunde\cite{noauthor_lambda_nodate}. Zusätzlich müssen pro 1.000.000 Ausführungen im Monat noch einmal 0,20 US-Dollar Anforderungsgebühren gezahlt werden.

\section{Konzeption der Testanwendung}
Als Testanwendung wird ein einfaches REST-Backend am Beispiel eines Notiz-Applikation entwickelt, wie es in der Praxis häufig verwendet wird. Der Service stellt folgende Routen bereit:  

\begin{enumerate}
    \item GET /notes: Das Auflisten aller verfügbarer Notizen
    \item GET /notes/\{id\}: Das Auflisten eines spezifischen Notiz mit der angegebenen id
    \item PUT /notes/\{id\}: Das Ändern einer spezifischen Notiz mit der angegebenen id
    \item POST /: Das Erstellen einer Notiz
\end{enumerate}

Um die Anwendung möglichst einfach zu gestalten und Unterschiede zwischen den beiden Technologien zu minimieren, wird zunächst auf die Verwendung einer Datenbank verzichtet. Stattdessen werden randomisierte Timeouts in allen Anfragen verwendet.
Als Runtime wird in beiden Fällen Node.js 12 verwendet.

\subsection{Serverless}
Für die Entwicklung der Serverless-Anwendung wird das populäre (36.000 Github-Stars) Serverless-Framework\cite{noauthor_serverless_nodate} verwendet. Dabei handelt es sich um ein Open-Source Framework zur Entwicklung von Serverless Anwendungen. Es übernimmt die Erstellung von Anwendungs-Stacks, Rechteverteilung und Konfiguration bei allen gängigen Public-Cloud Anbietern wie AWS, Azure oder GCP. Da in dieser Arbeit AWS verwendet wird, erstellt Serverless automatisch einen Anwendungs-Stack mit AWS CloudFormation. Dabei wird ein AWS API-Gateway erstellt, das über die Routen der REST-Schnittstelle verfügt. Trifft eine Anfrage an eine der Routen ein, übernimmt das API-Gateway die Auslösung des passenden Events, wodurch die korrekte Lambda-Funktion mit den vom Benutzer übergebenen Parametern aufgerufen wird. 

Durch die Nutzung des Frameworks wird die Erstellung der Anwendung vereinfacht. Denn auch wenn man sich nicht mehr um Server kümmern muss, ist dennoch die Konfiguration des API-Gateways notwendig.

\subsection{Container}
Für die Entwicklung der containerisierten Anwendung wird das Express Framework verwendet, das mit über 51.000 Github-Stars eines der meist verwendeten Web-Frameworks für Node.js ist. Die Anwendung wird unter Nutzung der Docker-Engine mittels einer Dockerfile in ein Container-Image gebaut. Dieses Image wird in der AWS Elastic Container Registry (ECR) gespeichert, um es von dort aus weiter zu verwenden. 
Die Ausführung der Anwendung erfolgt auf der AWS Elastic Container Service (ECS) Plattform, einem von AWS bereitgestelltem Orchestrations-Tool. Es wird AWS Fargate benutzt, um die Erstellung eines Server-Clusters weg zu abstrahieren. Des Weiteren wird ein Load Balancer verwendet, um die eingehenden Requests auf die verschiedenen Container zu verteilen. 

\section{Konzeption der Tests}

\subsection{Testing Tool}
Um die Performance der eben vorgestellten Anwendungen zu testen, wird die Performance-Testing Plattform k6 Cloud\cite{noauthor_load_nodate} verwendet. Dabei handelt es sich um ein cloudbasiertes Tool, mit der sich virtuelle Benutzer zum Testen einer Anwendung erstellen lassen. Die Benutzer arbeiten dann parallel vordefinierte Test-Szenarien ab, bei denen verschiedene Requests an die REST-APIs der Services geschickt werden. Das Tool speichert dabei für jeden Request an einen bestimmten API-Endpunkt Werte unter anderem folgender Metriken: 

\begin{enumerate}
    \item VUS (virtual users): Die aggregierte Anzahl der virtuellen Benutzer zum aktuellen Zeitpunkt 
    
    \item Response Time: Die Zeit vom Abschicken eines Requests bis zum Erhalt der Antwort in Millisekunden (ms). Dabei wird Aufwand für eventuelle DNS Lookups nicht mit einberechnet.
    
    \item HTTP-Statuscodes: Geben den Status eines HTTP-Requests an. Wichtig für die Betrachtung sind vor allem die Codes:
        \begin{enumerate}
            \item 200 (OK): Der Request war erfolgreich.
            \item 503 (Service Unavailable): Der Server kann den Request nicht bearbeiten. Kann auftreten, wenn zu viele Requests bei einem Service eintreffen und dieser aufgrund mangelnder verfügbarer Ressourcen (CPU / Speicher) nicht in der Lage ist, die Anfrage zu bearbeiten.
        \end{enumerate}
        
    \item Request Rate: Die aggregierte Anzahl aller bereits abgeschlossenen Requests pro Sekunde (req / s)
\end{enumerate}

Darüber hinaus bietet k6 mehrere Test-Typen an. Diese bestimmen, wie viele Benutzer zu welchen Zeitpunkt Anfragen an den Service stellen. Von den fünf angebotenen Typen sind die folgenden relevant:
\begin{enumerate}
    \item Load Testing: Dient der Evaluierung der System-Performance in Bezug auf die Anzahl der gleichzeitigen Benutzer oder der Requests-Rate.
    
    \item Stress Testing: Dient dazu, die Grenzen und Stabilität des Systems auszutesten
\end{enumerate}


Das Tool erlaubt in der kostenlosen Version maximal 50 gleichzeitige virtuelle Benutzer. Als Testing-Region, in der die VUS erstellt werden, wurde Paris ausgewählt, da die AWS Region eu-central-1 sich in Frankfurt am Main befindet. Paris ist somit noch nah genug aber nicht zu nah an den Rechenzentren auf dem die Services laufen.

\subsection{Test Szenarien}
Die folgenden Test Szenarien werden für die Analyse durchgeführt
\begin{itemize}
    \item Szenario A: Notiz bearbeiten \\
        Erst alle Notizen, dann eine einzelne Notiz abrufen und bearbeiten \\
        1. GET /notes -> 2s     \\
        2. GET /notes/1 -> 5s   \\
        3. PUT /notes/1         \\
        
    \item Szenario B: Notiz falsch erstellt \\
    Der Benutzer ruft alle Notizen ab. Er entscheidet sich eine Notiz erstellen. Er ruft die erstellte Notiz ab und bemerkt dass er einen Fehler gemacht hat. Er bearbeitet die Notiz und speichert die Notiz erneut ab. \\
        1. GET /notes   -> 10s  \\
        2. POST /notes  -> 3s   \\
        3. GET /notes/1 -> 5s   \\
        4. PUT /notes/1
\end{itemize}
