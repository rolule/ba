\chapter{Diskussion der Ergebnisse}
In diesem Kapitel sollen die Ergebnisse aus der vorangegangenen Analyse diskutiert werden.
Allgemein ist in den Experimenten deutlich geworden, dass die Performance der Container-Anwendung die der Lambda-Funktionen übertrifft. Die Antwortzeiten lagen bei der Nutzung eines Containers im Median in fast allen Tests bei ca. 60ms. Nur wenn die CPU-Auslastung eines Container sich dem Wert von 100 Prozent annäherte, stiegen die Response-Times an. Dagegen lagen die Werte der Lambda-Funktionen bspw. bei den Pipe-Clean Tests um den Wert 100ms. Allerdings konnte die Performance von Lambda mit einer größerer Anzahl an Requests verbessert werden. Bei den Load- und Stress-Tests konnten so mediane Antwortzeiten von in etwa 76ms erreicht werden. Die kleinste Request-Dauer überhaupt lag bei Lambda, Fehler ausgenommen, bei 69,99ms. Größere Ausreißer gab es bei beiden Technologien. Meist wurden diese durch Fehler verursacht. Während bei Fargate ausschließlich HTTP 502 (Bad Gateway) auftrat, sind bei Lambda sowohl HTTP 500 (Internal Server Error) und HTTP 504 (Gateway Timeout) Fehler vorzufinden. Ähnlich zu den verlängerten Antwortzeiten, sind die Fehler bei Fargate aber meistens nur bei hoher CPU-Auslastung ausgelöst worden. Es gab aber auch einzelne Ausfälle bei niedriger Auslastung. Zu einem kompletten Absturz des Servers oder HTTP 503 Statuscodes kam es in keinem Fall. 
Bei Lambda ist eine solche Auslastung durch die automatische Skalierung nicht möglich. Es ist daher sicher anzunehmen, dass die Fehler durch das API Gateway verursacht wurden und nichts mit den eigentlichen Funktionen zu tun haben. Generell traten aber bei beiden Services wenige Fehler auf. Die der Serverless-Anwendung sind allerdings mit einer Request-Dauer von bis zu 30 Sekunden als verheerender einzustufen.

Auch in der Varianz der Antwortzeit zeigten sich große Unterschiede der Technologien. Die Fargate-Container wiesen schon in den Pipe-Clean Tests eine äußerst geringe Abweichung vom Mittelwert auf. Bei allen Konfigurationen und für alle Use-Cases betrug der Variationskoeffizient dort nur etwa 0,01. Bei den Lambda-Funktionen hatte sowohl die Funktionsgröße als auch der Use-Case einen Einfluss auf die Ergebnisse. In den Pipe-Clean Tests wies Use-Case A einen Variationskoeffizient von ca. 0,23 bis 0,29 auf, während er bei Use-Case B zwischen 0,45 bis 0,52 schwankte. Bei Use-Case C waren es mit 0,59 bis 0,64 noch größere Abweichungen. Während in den Pipe-Clean Tests keine Unterschiede in der Varianz der unterschiedlichen Funktions-Konfigurationen auffielen, sah es bei den Stress- und Load-Tests anders aus. Die 128MB Variante zeigte im Stress Test mit 600 VUs noch einen Abweichungskoeffizient von 0,22 (Use-Case A), bei 256MB schrumpfte der Wert für den gleichen Test auf 0,17. Dies scheint im Zusammenhang mit der Funktions-Dauer zu stehen, deren maximaler Wert bei der kleineren Konfiguration fast bei 600ms lag, bei der größeren aber nur noch knapp 240ms betrug. Zwischen 256MB und 512MB Variante gab es allerdings keine Unterschiede mehr in der Abweichung vom Mittelwert, nur die maximale Funktionsdauer sank noch weiter.

\section{Beantwortung der Forschungsfragen (RQ1 - RQ5)}
Im folgenden sollen die in Kapitel 4 vorgestellten Forschungsfragen anhand in der Analyse festgestellter Ergebnisse beantwortet werden.

Um die Anzahl der nebenläufigen Lambda-Funktionen zu ermitteln, die dem maximalen Load eines Containers entsprechen (RQ1), wurden mehrere Stress-Tests durchgeführt. Für die 128MB und 256MB Container-Instanzen konnte für Use-Case A ein maximaler Load von ca. 700 virtuellen Benutzern ermittelt werden. In den anschließenden Load-Tests mit bis zu 600 Benutzern wurde eine Nebenläufigkeit von maximal 69 Funktionen festgestellt. Bei der 512MB Konfiguration wurde eine Grenze von etwa 1.400 parallelen Benutzern ermittelt. Bei den Load-Tests mit 1.200 Benutzern konnten bis zu 137 Lambda-Funktionen registriert werden. 
Für die anderen Use-Cases lag die Request-Rate deutlich unter der von Use-Case A. Das führte darum ebenso zu einer geringeren Nebenläufigkeit mit 60 bzw. 103 bei Use-Case B. Daher sollte bei zukünftigen Experimenten von einer ähnlichen Request-Rate anstatt einer gleichen Anzahl der Benutzer ausgegangen werden.
Darüber hinaus ist die Nebenläufigkeit von Lambda-Funktionen abhängig von der Laufzeit der Funktion, welche bei diesen Experimenten auf mindestens 50ms beschränkt war und darum in einer anderen Anwendung auch stark variieren könnte. In Zukunft könnten daher verschieden in ihrer Laufzeit beschränkte Lambda-Funktionen auf ihre Nebenläufigkeit untersucht werden.
Forschungsfrage RQ1 lässt sich also nicht eindeutig beantworten, da sie sich als deutlich anwendungsspezifisch erwiesen hat. Es lässt sich aber feststellen, dass eine einzige Container-Instanz durchaus mehreren Hunderten, evtl. sogar Tausenden Lambda-Funktionen entsprechen kann.

Für die Forschungsfrage RQ2 wurden die beiden Anwendungen Load-Tests mit unterschiedlich schnellem Anstieg der Benutzerzahlen unterzogen. Es wurde vermutet, dass die Performance unter schnellem Anstieg bei beiden Systemen evtl. schlechter als die bei langsamen Anstieg wäre (H1). Für die Performance des Containers konnte in den Experimenten keine Veränderung festgestellt werden. Bei den Lambda-Funktionen zeigte sich ein differenziertes Bild. Die Spike-Tests der 128MB Variante lösten einen verzögerten Anstieg der Antwortzeiten aus, welche bei Use-Case A noch ähnlich denen des Load-Tests, bei Use-Case B jedoch deutlich über denen des Load-Tests lagen. Bei den 256MB konnte nur noch für Use-Case C ein geringer Unterschied festgestellt werden und bei den 512MB Funktionen war gar keine Diskrepanz zwischen schnellem und langsamen Anstieg erkennbar. Bei größeren Nutzerzahlen könnte dieser Effekt jedoch eventuell größer ausfallen. Die Hypothese H1 kann also nur teilweise bestätigt werden. Es ist weitere Forschung des Phänomens nötig, um die genauen Umstände zu klären.

Die Forschungsfrage RQ3 befasste sich mit der Nutzung größerer RAM und CPU-Werten für sowohl die Container-Anwendung als auch die Lambda-Funktionen. Vermutet wurde, dass bei einer Verdopplung der Container-vCPUs auch doppelt so viele Anfragen verarbeitet werden können. Dies konnte teilweise bestätigt werden. Bei einem Wechsel von 128MB auf 256MB konnte keine Veränderung der maximalen Benutzerzahlen festgestellt werden. Beide Container konnten z.B. für Use-Case A etwa 700 Benutzer bedienen, bevor die Antwortzeiten anstiegen. Vermutlich hängt dies damit zusammen, dass beide die gleichen Task-Gruppe von 512MB RAM und 0,25 vCPU zugewiesen bekamen. Dies war jedoch nötig, da AWS Fargate keine geringere Task-Gruppierung mit bspw. 128MB RAM und 0,125 vCPU zur Verfügung stellt. Um dieses Problem auszugleichen wurden beiden Containern harte Limits für CPU und RAM gesetzt. Es wird vermutet, dass die Limits ignoriert wurden und deshalb beide Zugang zu 0,25 vCPU hatten. 
Im Gegensatz dazu konnte beim Wechsel von 256MB auf 512MB die Hypothese (H2) bestätigt werden. Während der 256MB Container bei Use-Case A noch ein Limit von ca. 700 VUs hatte, konnten beim 512MB Container (mit 0,5 vCPU) in etwa 1.400 VUs, also in etwa doppelt so viele Benutzer vor Steigen der Antwortzeit bedient werden. Daher kann die Hypothese teilweise bestätigt werden.

Für die Forschungsfrage RQ4 wurde die Performance von mehreren Container-Instanzen zu der von einzelnen Containern in Beziehung gestellt. Die Hypothese H3 war, dass die Anzahl der möglichen Requests mit jeder hinzugefügten Instanz linear ansteigt. Dies konnte mit Stress-Tests von zwei 256MB Instanzen und einer 512MB Instanz gezeigt werden, die ungefähr die gleichen Limits an Benutzerzahlen aufwiesen. Die Annahme kann also bestätigt werden.

Die letzte Hypothese war, dass sich ein Use-Case mit mehreren Endpunkten aufgrund der vermehrten Coldstarts negativ auf die Antwortzeiten der Lambda-Anwendung auswirkt (H4). Wie erwartet konnte bei der Container-Anwendung keine Veränderung festgestellt werden. Bei der Lambda-Funktion trat in den Pipe-Clean Tests kein Unterschied zwischen den Use-Cases auf, was darauf zurückzuführen ist, dass nur ein Coldstart benötigt wurde. 
Anders sieht es bei den Stress- und Load-Tests aus. Dort hatte die Anzahl der Endpunkte durchaus einen Einfluss auf die Entwicklung der Antwortzeit. Bei den Stress-Tests der 128MB Funktionen sinken die Antwortzeiten bei mehreren Endpunkten langsamer auf das untere Niveau ab als die der mit einem Endpunkt. Bei den größeren Funktionen trat dieser Effekt nicht auf. Allerdings erreichen die Use-Cases mit mehreren Endpunkten in fast allen Load- und Stress-Tests eine allgemein höhere Antwortzeit. Es traten aber auch Schwankungen auf, bei denen bspw. der Verlauf von Use-Case B unter dem von Use-Case A lag. Tendenziell bestätigt aber der Vergleich der jeweils besten Verläufe die Hypothese H4.

\section{Skalierung und Optimierung}
Da Container auf jedem Computersystem mit Unterstützung einer Container-Runtime betrieben werden können, bieten sich vielfältige Wege an eine Container-Anwendung zu betreiben und zu skalieren. Deshalb kann in dieser Arbeit nicht auf alle eingegangen werden. Meist wird ein Container-Orchestrations-Tool verwendet, um das manuelle Verteilen der Container auf Computer-Clustern zu vermeiden. Bei Kubernetes gibt es den Horizontal Pod Autoscaler (HPA), der die automatische Skalierung von Pods in Abhängigkeit der CPU-Auslastung ermöglicht\cite{noauthor_horizontal_nodate-1}. Auch bei Nutzung des AWS Elastic Kubernetes Service (EKS) ist ein automatische Skalierung möglich\cite{noauthor_horizontal_nodate}. Auch die Nutzung eines Vertical Pod Autoscaler (VPA) ist möglich, der automatisch die Ressourcen einzelner Container skaliert\cite{noauthor_vertical_nodate}. Es kann auch ein Cluster Autoscaler verwendet werden, um zusätzlich zu der Anzahl der Container auch die Anzahl der Kubernetes-Knoten hoch zu skalieren\cite{noauthor_cluster_nodate}.
Auf die Performance-Tests all dieser Konfigurationen kann in dieser Arbeit unmöglich eingegangen werden, da es zu diesem Thema zu viele Möglichkeiten und auch Wege zur Optimierung gibt. Beispielsweise lässt sich die Schwelle der CPU-Auslastung einstellen, ab der die Anzahl der Container hoch- oder runter-skaliert werden soll. Liegt die Schwelle zu niedrig, skaliert das System evtl. zu früh und die Kosten steigen. Liegt die Schwelle zu hoch, skaliert das System evtl. zu spät und die Performanz sinkt.

In dieser Arbeit wurde AWS ECS mit dem Fargate-Starttyp verwendet, um die Einstellung eines Clusters nicht vornehmen zu müssen. Fargate verwaltet die Knoten des Clusters automatisch. Der ordinäre Weg der Cluster-Erstellung wäre es, mehrere Virtuelle Maschinen zu starten, zu konfigurieren und jede dem Cluster zuzuweisen. Durch die Nutzung von Fargate kann die Konfiguration von Container-Clustern also erheblich vereinfacht werden. ECS und Fargate bieten mit Auto-Scaling auch eine Möglichkeit der automatischen Skalierung an. Diese funktioniert zusammen mit AWS CloudWatch Alarmen. Dazu lässt sich eine von zwei verschiedenen Policies einstellen.

Bei einer Step Scaling Policy lassen sich, ähnlich wie bei Kubernetes HPA, Grenzen für die Skalierung auf Basis von CloudWatch Metriken, also bspw. CPU- oder Arbeitsspeicher-Auslastung, festlegen. CloudWatch überprüft dann in bestimmten Intervallen die Metriken und schlägt Alarm, wenn eine Metrik über oder unter dem spezifizierten Schwellwert liegt. Fargate reagiert auf den Alarm und skaliert die Anzahl der Container innerhalb des Clusters hoch oder herunter. 

Bei einer Target Tracking Policy, lässt sich für Metriken ein Ziel festlegen, das eingehalten werden soll. Beispielweise könnte man ein Ziel von 75\% CPU-Auslastung festlegen. Mithilfe der CloudWatch Alarme wird dann versucht, dieses Ziel möglichst einzuhalten. 

Problematisch ist allerdings die Größe des Intervalls, in dem die Metriken überprüft werden können. Standardmäßig kann dies nur alle fünf Minuten erfolgen. Träfe die Container-Anwendung eine plötzliche Spitzenlast, würde es fünf Minuten dauern, bis reagiert und die Kapazität erhöht werden könnte. Nach Absprache mit AWS kann sich dieses Intervall auf eine Minute senken lassen. Dies ist allerdings, verglichen mit den Skalierungsmöglichkeiten von AWS Lambda, noch immer zu langsam für Anwendungen die hochverfügbar sein müssen.

Wichtig für eine schnelle Skalierung ist vor allem auch die Größe des Containers-Abbilds. Da bei jeder neu hinzugefügten Container-Instanz das Container-Image von der Registry heruntergeladen werden muss, ist es notwendig, die Image-Größe möglichst zu minimieren. Zum Einsatz kommende Techniken sind hierbei beispielsweise die Nutzung eines Alpine-Images als Basis-Image, einer besonders kleinen Linux-Distribution, Multi-Stage Builds, mit denen unnötige Dateien entfernt werden können oder Layer-Merging, bei dem die Anzahl der Docker-Layer minimiert wird.
In Zukunft können also noch viele Aspekte des Skalierungsverhaltens und der Optimierung von Container-Anwendungen mit Performance Tests untersucht werden. 

Auch das Skalierungsverhalten von Lambda-Funktionen kann mit Autoscaling und provisionierter Nebenläufigkeit variiert werden. Lambda ist ein von Natur aus horizontal skalierendes System, daher müssen vom Entwickler theoretisch keine Einstellungen vorgenommen werden, um eine hochverfügbare Anwendung zu schaffen. Um auch Cold-Starts möglichst zu vermeiden, lässt sich die gewollte Nebenläufigkeit allerdings auch schon vor einem Benutzer-Ansturm definieren (Provisioned Concurrency). Lambda startet dann bereits Funktionen vor, die dann bei Bedarf keinen Kaltstart mehr erfordern, sondern direkt einen Warmstart durchführen können. Kombinieren lässt sich dies mit Autoscaling, um die provisionierte Kapazität an steigende Anfragezahlen anzupassen. 

Auch die Größe des Arbeitsspeicher einer Lambda-Funktion kann einen Einfluss auf das Skalierungsverhalten nehmen. Da eine Funktion mit größerem Speicher auch mehr CPU zugewiesen bekommt, können Anfragen, bei besonders CPU-intensiven Aufgaben, schneller verarbeitet werden und es werden eventuell weniger nebenläufige Funktionen und damit weniger Cold-Starts benötigt. Es gibt Tools wie "`AWS Lambda Power Tuning"'\cite{casalboni_alexcasalboniaws-lambda-power-tuning_2021}, die es für solche Funktionen ermöglichen, die beste Konfiguration zu finden.

Es gibt darüber hinaus vielfältige Wege, die Coldstart Zeit einer Lambda-Funktion zu verringern. Ähnlich zum Docker-Container, hat auch die Größe einer Lambda-Funktion Einfluss auf die Startzeit. Denn bei jedem Coldstart muss der Funktions-Code in den Lambda-Container geladen werden. Bei einigen Programmiersprachen wie Java oder .NET macht ebenfalls die Konfiguration des Lambda-Arbeitsspeichers einen großen Unterschied\cite{malishev_aws_2019}. 

\section{Kosten}
In Sektion \ref{sec:kosten} wurden die Kostenmodelle der beiden genutzten Services verglichen. Es wurden Formeln zur Abschätzung der Nutzungskosten eines Services für einen Monat vorgestellt. Der große Unterschied zwischen beiden Technologien liegt in der Abrechnung der tatsächlich verwendeten Rechenzeit. Während bei Lambda nur die Laufzeit einer Funktion im Millisekunden-Bereich abgerechnet wird, zahlt man pro Container einen Preis für seine gesamte Laufzeit - auch wenn er keine Anfragen bearbeitet. Im Falle eines Containers bezahlt man also gleich viel wenn er mehr oder weniger ausgelastet ist. Vor allem zu Zeiten in denen die Auslastung gering ist, bspw. in der Nacht, ist die Nutzung eines Containers ein großer Nachteil. Der Vorteil von Lambda liegt darin, dass bei geringer Nutzung auch nur wenige Kosten anfallen. 
Im Gegensatz dazu, kann bei einer hohen Last die Nutzung eines Container erheblich günstiger sein als eine Lambda-Anwendung, denn die Kosten pro einer Millionen Aufrufe des API-Gateways fallen schwer ins Gewicht. Bei welcher Technologie man weniger bezahlt, hängt also von der Auslastung der Anwendung ab. Wie in Sektion \ref{subsec:kosten-lambda} gezeigt wurde, lässt sich ungefähr bestimmen, wie viele monatliche Requests mit Lambda und API Gateway möglich sind, bevor die Kosten die eines einzelnen Containers überschreiten. Andererseits hat ein Container eine Grenze, wie viele Requests er pro Sekunde verarbeiten kann, bevor ein weiterer Container hinzugezogen werden (skaliert werden) muss. Für jeden weiteren Container fallen dann auch weitere Kosten an, allerdings nur so lange er benötigt wird. Dafür müssen aber auch unter Umständen komplizierte Skalierungs-Konfigurationen erstellt werden, was bei Lambda nicht unbedingt notwendig ist. Hinzu kommen ebenso die ungewissen Nutzungskosten eines Load Balancers. Welche Technologie das bessere Preis-Leistungs-Verhältnis aufweist, lässt sich also nur im Einzelfall bestimmen. Ist die Anzahl der Anfragen oder der Benutzer der Anwendung bekannt, kann es aber für Organisationen hilfreich sein, die Kosten mit den vorgestellten Formeln abzuschätzen und mit Performance-Tests zu evaluieren, um die passendere Alternative auszuwählen. 

Um Prinzip P8 zu erfüllen, werden im folgenden die tatsächlich für diese Arbeit angefallenen Kosten angegeben, um für eine erneute Durchführung der Experimente eine Einschätzung der nötigen Ressourcen zu geben.
Insgesamt fielen für die Tests dieser Arbeit laut des AWS Cost Explorers ca. 80 Euro für die Nutzung des API Gateways an. Für Lambda waren es nur ca. 4 Euro. Die Gesamtkosten der Serverless-Anwendung berufen sich also auf ungefähr 85 Euro.
Im Gegensatz dazu wurden für die Container Anwendung nur ca. 15 Euro fällig, davon ca. fünf Euro für ECS mit Fargate und ca. zehn Euro für den Elastic Load Balancer.
Zusätzlich müssen noch Kosten in Höhe von ca. 25 Euro für die EC2-Instanzen, die als Load-Generator fungierten, hinzugerechnet werden.
Die Durchführung aller Tests in dieser Arbeit, veranschlagt also insgesamt Kosten von ca. 124 Euro.

\section{Implikationen für die Praxis}
Durch die in dieser Arbeit durchgeführten Experimente wurde deutlich, dass die Performance eines Container-Backends auf AWS Fargate zwar der einer Serverless-Anwendung auf AWS Lambda und API Gateway in Bezug auf die Antwortzeiten überlegen ist. Allerdings liegt der Unterschied der beiden Technologien nur im Bereich von einigen Millisekunden. Wird eine zeitkritische oder in ihren Antwortzeiten konsistente Anwendung benötigt, bspw. eine Banking- oder Trading-Plattform, sollte dennoch eher die Verwendung einer Container-Architektur erwägt werden.

Lambda bietet ein stabiles Skalierungsverhalten, bei dem nach anfänglichen, durch Coldstarts bedingten, Spitzenwerten der Antwortzeiten, beinahe konsistente Werte erreicht werden und das auch bei schnellem Last-Anstieg gut zu funktionieren scheint. Auch Container lassen sich skalieren, jedoch muss der nicht zu vernachlässigende Aufwand der konkreten Implementierung des Skalierungsverhaltens beachtet werden. Wird ECS ohne Fargate oder ein Kubernetes-Service verwendet, muss sich zusätzlich um die Konfiguration des Clusters gekümmert werden. All das wird von Lambda vollständig übernommen, was zu enormen Einsparungen an Entwicklungskosten führen könnte. Ist bereits eine Container-Architektur für den Betrieb einer anderen Anwendung aufgebaut worden oder die Nutzung begleitender containerisierter Services (z.B. einer bestimmten Datenbank) unabdingbar, kann eine Container-Anwendung vorzuziehen sein. Auch die Nutzung von Fargate erleichtert den Betrieb von Container-Clustern, führt aber zu Einschränkungen des Skalierungsverhaltens.

Zusätzlich muss bei den Service-Kosten abgewogen werden, welche Technologie für einen konkreten Anwendungsfall und der normalen Last der Anwendung besser geeignet ist. Bei konstanter, relativ hoher Last auf dem Service ist es wahrscheinlich, dass das API Gateway erhebliche Kosten verursacht und die Nutzung eines oder mehrerer Container sich als wirtschaftlicher erweist. Hier könnte man die Verwendung von alternativen API Gateways, bspw. Kong\cite{noauthor_kongkong_2021}, erwägen. Das Gebühren für das Hosting und die Integration dieser Alternativen muss hierbei aber auch betrachtet werden. Bei nur kurzzeitig hoher Spitzenlast oder geringer Nutzung des Services ist in Bezug auf die Gebühren vermutlich die Nutzung der FaaS-Anwendung geeigneter, da ansonsten für nicht genutzte Kapazität des Containers gezahlt werden muss. 
Besonders bei der erstmaligen Einführung einer Anwendung könnte es aufgrund der unbekannten Nutzungsrate günstiger sein, ein Serverless-Backend zu verwenden, um nicht für ungenutzte Kapazität zahlen zu müssen. Ist die Last bekannt, können die Kosten der bestehenden Anwendung evaluiert werden und eventuell eine Container-Architektur aufgebaut werden.
Des Weiteren ist zu empfehlen, kontinuierlich die Last seiner Anwendung zu überwachen und mit dem Einsatz verschiedener Technologien wie Fargate oder Lambda zu experimentieren, um Kosten in der Entwicklung und beim Betrieb der Anwendung einzusparen. Es wird vorgeschlagen, die Kernfunktionalität des Backends zu extrahieren, um sie in beiden Services nutzbar zu machen. Diese könnten dann in einer Art A/B-Testing Strategie parallel oder abwechselnd betrieben und dauerhaft evaluiert werden.

\section{Ausblick}
Es gibt viele verschiedene Variablen die Einfluss auf die Performance von Serverless- und Containerisierten-Anwendungen nehmen können. Beispielsweise könnte das in dieser Arbeit genutzte 50ms Timeout variiert werden oder durch Nutzung echter Services wie z.B. DynamoDB ersetzt werden. In dieser Arbeit wurde sich auf die Performance eines REST-Backends beschränkt. Dabei wurden verschiedene Container und Lambda-Größen untersucht und unterschiedliche Test-Szenarien durchgeführt. Es konnten aber unmöglich alle verschiedenen Konfigurationen betrachtet und evaluiert werden. Beispielsweise lassen sich die sowohl die Größen der Lambda-Funktionen als auch der Container-Instanzen noch auf mehrere Gigabyte erweitern. Des Weiteren, lassen sich Container auf viele verschiedene Wege deployen und betreiben, z.B. auf einem selbst gemanagten EC2 Cluster, mit ECS, einem EKS Cluster oder Elastic Beanstalk. Dazu gehört ebenfalls die Betrachtung des unter Umständen komplexe Skalierungsverhaltens einer Container-Anwendung.

Immer häufiger werden auch Mischformen von Container und Serverless. Beispielsweise bietet AWS seit Ende 2020 an, Container über AWS Lambda verfügbar zu machen\cite{noauthor_aws_nodate-1}. Darüber hinaus könnten Container und FaaS-Angebote verschiedener Cloud-Anbieter verglichen werden, zum Beispiel von Microsoft Azure oder Google Cloud Platform.

Die in dieser Arbeit durchgeführten Tests waren auf eine einzige Beispielanwendung beschränkt. Es lassen sich aber für jede beliebige Anwendung Performance-Tests durchführen. In Zukunft könnte das für diese Arbeit genutzte Testing-System daher ausgebaut werden, damit es für jede beliebige Anwendungs-Architektur nutzbar ist. In das Analyse-System könnten weitere Metriken aus AWS CloudWatch, wie z.B. die tatsächlichen Funktions-Kosten, integriert werden und somit den Vergleich beider Technologien noch weiter verbessern. Auch auf andere Services wie AWS EKS oder Elastic Beanstalk könnte das Performance-Testing-Tool ausgeweitet werden. Dies kann Organisationen dabei helfen, die Nutzung ihrer Technologien besser zu evaluieren.
