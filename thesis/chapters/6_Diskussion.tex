\chapter{Diskussion der Ergebnisse}
In diesem Kapitel sollen die Ergebnisse aus der vorangegangenen Analyse diskutiert werden.
Allgemein ist in den Experimenten deutlich geworden, dass die Performance der Container-Anwendung die der Lambda-Funktionen übertrifft. Die Antwortzeit lag im Median bei fast allen Tests bei ca. 60ms. Nur wenn die CPU-Auslastung eines Container an die 100 Prozent erreichte, stiegen die Response-Times an. Dagegen lagen die Werte der Lambda-Funktionen bspw. bei den Pipe-Clean Tests um den Wert 100ms. Allerdings konnte die Performance von Lambda mit einer größerer Anzahl an Requests verbessert werden. Bei den Load- und Stress-Tests konnte so mediane Antwortzeiten von 76ms erreicht werden. Die kleinste Request-Dauer überhaupt lag bei Lambda, Fehler ausgenommen, bei 69,99ms. Größere Ausreißer gab es bei beiden Technologien. Meist wurden diese durch Fehler verursacht. Während bei Fargate ausschließlich HTTP 502 (Bad Gateway) auftritt, sind bei Lambda sowohl HTTP 500 (Internal Server Error) und HTTP 504 (Gateway Timeout) Fehler vorzufinden. Ähnlich zu den verlängerten Antwortzeiten sind die Fehler bei Fargate aber meistens nur bei hoher CPU-Auslastung ausgelöst worden. Es gab aber auch einzelne Ausfälle bei niedriger Auslastung. Zu einem kompletten Absturz des Servers oder HTTP 503 Statuscodes kam es in keinem Fall. 
Bei Lambda ist eine solche Auslastung durch die automatische Skalierung nicht möglich. Es ist daher sicher anzunehmen, dass die Fehler durch das API Gateway verursacht wurden und nichts mit den eigentlichen Funktionen zu tun haben. Generell traten aber bei beiden Services wenige Fehler auf. Die von Lambda sind allerdings mit einer Request-Dauer von bis zu 30 Sekunden als verheerender einzustufen.

Auch in der Varianz der Antwortzeit zeigen sich große Unterschiede der Technologien. Die Fargate Container zeigten schon in den Pipe-Clean Tests eine geringe Abweichung vom Mittelwert. Bei allen Konfigurationen und für alle Use-Cases betrug der Variationskoeffizient ca. 0,01. Bei den Lambda-Funktionen zeigte sich ein anderes Bild. Hier hatte sowohl die Funktionsgröße als auch der Use-Case einen Einfluss auf die Ergebnisse. In den Pipe-Clean Tests zeigte sich, dass Use-Case A einen Variationskoeffizient von ca. 0,23 bis 0,29 aufweist, während er bei Use-Case B zwischen 0,45 bis 0,52 schwankt. Während in den Pipe-Clean Tests keine Unterschiede zwischen den unterschiedlichen Funktions-Konfigurationen auffielen, sah es bei den Stress- und Load-Tests anders aus. Die 128MB Variante zeigte im Stress Test mit 600 VUs noch einen Abweichungskoeffizient von 0,22 (Use-Case A), während der Wert bei 256MB für den gleichen Test auf 0,17 schrumpfte. Dies scheint im Zusammenhang mit der Funktions-Dauer zu stehen, deren maximaler Wert bei der kleineren Konfiguration fast bei 600ms lag; bei der größeren aber nur noch knapp 240ms betrug. Zwischen 256MB und 512MB Variante gab es dann aber keine Unterschiede mehr in der Abweichung vom Mittelwert.

\section{Beantwortung der Forschungsfragen (RQ1 - RQ5)}
Im folgenden sollen die in Kapitel 4 vorgestellten Forschungsfragen anhand in der Analyse festgestellter Ergebnisse beantwortet werden.

Um die Anzahl der nebenläufigen Lambda-Funktionen zu ermitteln, die dem maximalen Load eines Containers entsprechen (RQ1), wurden mehrere Stress-Tests durchgeführt. Für die 128MB und 256MB Container-Instanzen konnte für Use-Case A ein maximaler Load von ca. 700 virtuellen Benutzern ermittelt werden. In den anschließenden Load-Tests mit bis zu 600 Benutzern wurde eine Nebenläufigkeit von maximal 69 Funktionen festgestellt. Bei der 512MB Konfiguration wurde eine Grenze von etwa 1.400 parallelen Benutzern ermittelt. Bei den Load-Tests mit 1200 Benutzern konnten bis zu 137 Lambda-Funktionen registriert werden. 
Für die anderen Use-Cases lag die Request-Rate deutlich unter der von Use-Case A. Das führte darum ebenso zu einer geringeren Nebenläufigkeit mit 60 bzw. 103 bei Use-Case B. 
Forschungsfrage RQ1 lässt sich also nicht eindeutig beantworten, da sich kein erkennbares Muster abzeichnet und die Zahlen zwischen gleichen Experimenten deutlich abweichen können. Darüber hinaus ist die Nebenläufigkeit von Lambda-Funktionen abhängig von der Laufzeit der Funktion, welche bei diesen Experimenten auf mindestens 50ms beschränkt war und darum in einer anderen Anwendung auch stark variieren könnte. Es lässt sich aber für RQ1 sagen, dass eine einzige Container-Instanz durchaus mehreren Hunderten, evtl. sogar Tausenden Lambda-Funktionen entsprechen kann.

Für die Forschungsfrage RQ2 wurden die beiden Anwendungen Load-Tests mit unterschiedlich schnellem Anstieg der Benutzerzahlen unterzogen. Es wurde vermutet, dass die Performance unter schnellem Anstieg bei beiden Systemen evtl. schlechter als die bei langsamen Anstieg wäre. Für die Performance des Containers konnte in den Experimenten keine Veränderung festgestellt werden. Bei den Lambda-Funktionen zeigte sich ein differenziertes Bild. Die Spike-Tests der 128MB Variante lösten einen verzögerten Anstieg der Antwortzeiten aus, welche bei Use-Case A noch ähnlich denen des Load-Tests, bei Use-Case B jedoch deutlich über denen des Load-Tests lagen. Bei den 256MB und 512MB Funktionen konnte jedoch überhaupt kein Unterschied zwischen schnellem und langsamen Unterschied festgestellt werden. Bei größeren Nutzerzahlen könnte dieser Effekt jedoch größer ausfallen.

Die Forschungsfrage RQ3 befasste sich mit der Nutzung größerer RAM und CPU-Werten für sowohl die Container-Anwendung als auch die Lambda-Funktionen. Vermutet wurde, dass bei einer Verdopplung der Container-CPU auch doppelt so viele Anfragen verarbeitet werden können. Dies konnte teilweise bestätigt werden. Bei einem Wechsel von 128MB auf 256MB konnte keine Veränderung der maximalen Benutzerzahlen festgestellt werden. Beide Container konnten für Use-Case A etwa 700 Benutzer bedienen, bevor die Antwortzeiten anstiegen. Vermutlich hängt dies damit zusammen, dass beide die gleichen Task-Gruppe von 512MB RAM und 0,25 vCPU zugewiesen bekamen. Dies war jedoch nötig, da AWS Fargate keine geringere Task-Gruppierung mit bspw. 128MB RAM und 0,125 vCPU zur Verfügung stellt. Um dieses Problem auszugleichen wurden beiden Containern harte Limits für CPU und RAM gesetzt. Es wird vermutet, dass die Limits ignoriert wurden und deshalb beide Zugang zu 0,25 vCPU hatten. Im Gegensatz dazu konnte beim Wechsel von 256MB auf 512MB die Hypothese (H2) bestätigt werden. Während der 256MB Container bei Use-Case A noch ein Limit von ca. 700 VUs hatte, konnten beim 512MB Container (mit 0,5 vCPU) in etwa 1400 VUs, also in etwa doppelt so viele Benutzer vor Steigen der Antwortzeit bedient werden. Daher kann die Hypothese teilweise bestätigt werden.

Für die Forschungsfrage RQ4 wurde die Performance von mehreren Container-Instanzen zu der von einzelnen Containern in Beziehung gestellt. Die Hypothese H3 war, dass die Anzahl der möglichen Requests mit jeder hinzugefügten Instanz linear ansteigt. Dies konnte mit Stress-Tests von zwei 256MB Instanzen und einer 512MB Instanz gezeigt werden. Die Hypothese kann also bestätigt werden.

Die letzte Hypothese war, dass sich ein Use-Case mit mehreren Endpunkten aufgrund der vermehrten Coldstarts negativ auf die Antwortzeiten der Lambda-Anwendung auswirkt (H4). Wie erwartet konnte bei der Container-Anwendung keine Veränderung festgestellt werden. Bei der Lambda-Funktion trat in den Pipe-Clean Tests kein Unterschied zwischen den Use-Cases auf. 
Anders sieht es bei den Stress- und Load-Tests aus. Dort hatte die Anzahl der Endpunkte durchaus einen Einfluss auf die Entwicklung der Antwortzeit. Bei den Stress-Tests sinken die Antwortzeiten der Funktionen mit mehreren Endpunkten langsamer auf das untere Niveau ab als die der mit einem Endpunkt. Und bei den Load-Tests erreichen die Use-Cases eine allgemein höhere Antwortzeit.
Die Hypothese H4 kann also bestätigt werden.

\section{Kosten}
In Sektion \ref{sec:kosten} wurden die Kostenmodelle der beiden Services verglichen. Es wurden Formeln zur Abschätzung der Nutzungskosten eines Services für einen Monat vorgestellt. Der große Unterschied zwischen beiden Technologien liegt in der Abrechnung der tatsächlich verwendeten Rechenzeit. Während bei Lambda nur die Laufzeit einer Funktion im Millisekunden-Bereich abgerechnet wird, zahlt man pro Container einen Preis für seine gesamte Laufzeit - auch wenn er keine Anfragen bearbeitet. Im Falle eines Containers bezahlt man also gleich viel wenn er mehr oder weniger ausgelastet ist. Vor allem zu Zeiten in denen die Auslastung gering ist, bspw. Nachts, ist die Nutzung eines Containers ein großer Nachteil. Der Vorteil von Lambda liegt darin, dass bei wenig Nutzung auch nur wenig zu zahlen ist. Bei einer hohen Auslastung kann ein Container allerdings erheblich günstiger sein als eine Lambda-Anwendung, denn die Kosten pro einer Millionen Aufrufe des API-Gateways fallen schwer ins Gewicht. Bei welcher Technologie man weniger bezahlt hängt also von der Auslastung der Anwendung ab. Wie in Sektion \ref{subsec:kosten-lambda} gezeigt wurde, lässt sich ungefähr bestimmen, wie viele monatliche Requests mit Lambda möglich sind, bevor es teurer wird als ein einzelner Container. Andererseits hat ein Container eine Grenze, wie viele Requests er pro Sekunde verarbeiten kann, bevor ein weiterer Container hinzugezogen werden (skaliert werden) muss. Für jeden weiteren Container fallen dann auch weitere Kosten an, allerdings nur so lange er benötigt wird. Dafür müssen aber auch unter Umständen komplizierte Skalierungs-Konfigurationen erstellt werden, was bei Lambda nicht unbedingt notwendig ist. Welche Technologie das bessere Preis-Leistungs-Verhältnis aufweist, lässt sich also nur im Einzelfall bestimmen.

Insgesamt fielen für die Tests dieser Arbeit laut dem AWS Cost Explorer ca. 80 Euro für die Nutzung des API Gateways an. Für Lambda waren es nur ca. 4 Euro. Die Gesamtkosten der Serverless-Anwendung berufen sich also auf ungefähr 85 Euro.
Im Gegensatz dazu wurden für die Container Anwendung nur ca. 15 Euro fällig, davon ca. fünf Euro für ECS mit Fargate und ca. zehn Euro für den Elastic Load Balancer.
Zusätzlich müssen noch Kosten in Höhe von ca. 25 Euro für die EC2-Instanzen, die als Load-Generator fungierten, hinzugerechnet werden.
Die Durchführung aller Tests in dieser Arbeit, veranschlagt also insgesamt Kosten von ca. 124 Euro.

\section{Implikationen für die Praxis}
Durch die in dieser Arbeit durchgeführten Experimente wurde deutlich, dass die Performance eines Container-Backends auf AWS Fargate zwar der einer Serverless-Anwendung auf AWS Lambda in Bezug auf die Antwortzeit überlegen ist. Allerdings liegt der Unterschied der beiden Technologien nur im Bereich von einigen Millisekunden. Wird eine zeitkritische Anwendung benötigt, also z.B. eine Banking- oder Trading-Plattform, sollte dennoch eher die Verwendung einer Container-Architektur erwägt werden.

Lambda bietet ein stabiles Skalierungsverhalten, das auch bei Spitzenlasten gut funktioniert. Auch Container lassen sich skalieren, jedoch ist ein nicht zu vernachlässigender Aufwand der konkreten Implementierung des Skalierungsverhaltens zu beachten. Wird ECS ohne Fargate oder ein Kubernetes-Service verwendet, muss sich zusätzlich um die Konfiguration des Clusters gekümmert werde. All das wird von Lambda vollständig übernommen, was zu enormen Einsparungen an Projektkosten führen könnte. 

Zusätzlich muss bei den Service-Kosten für den konkrete Anwendungsfall abgewogen werden, welche Technologie besser geeignet ist. Bei konstanter relativ hoher Last auf dem Service ist es wahrscheinlich, dass das API Gateway erhebliche Kosten verursacht und die Nutzung eines oder mehrerer Container sich wirtschaftlicher erweist. Bei nur kurzzeitig hoher Spitzenlast oder geringer Nutzung des Services ist in Bezug auf die Gebühren vermutlich die Nutzung der FaaS-Anwendung geeigneter, da sonst für nicht genutzte Kapazität des Containers bezahlt werden muss. 
Es ist also empfehlen, kontinuierlich die Last seiner Anwendung zu überwachen und mit dem Einsatz verschiedener Technologien wie Fargate oder Lambda zu experimentieren um Kosten in der Entwicklung und beim Betrieb der Anwendung zu sparen.

\section{Ausblick}
Es gibt viele verschiedene Variablen die Einfluss auf die Performance von Serverless- und Containerisierten-Anwendungen nehmen können. Beispielsweise könnte das in dieser Arbeit genutzte 50ms Timeout variiert werden oder durch Nutzung echter Services wie z.B. DynamoDB ersetzt werden. In dieser Arbeit wurde sich auf die Performance eines REST-Backends beschränkt. Dabei wurden verschiedene Container und Lambda-Größen untersucht und unterschiedliche Test-Szenarien durchgeführt. Es konnten aber unmöglich alle verschiedenen Konfigurationen betrachtet und evaluiert werden. Beispielsweise lassen sich die sowohl die Größen der Lambda-Funktionen als auch der Container-Instanzen noch auf mehrere Gigabyte erweitern. Container lassen sich auf viele Wege deployen und betreiben, z.B. auf einem selbst gemanagten EC2 Cluster, mit ECS, einem EKS Cluster oder Elastic Beanstalk. Dazu gehört ebenfalls das unter Umständen komplexe Skalierungsverhalten einer Container-Anwendung.

Da Container auf jedem Computer mit Unterstützung einer Container-Runtime laufen können, bieten sich vielfältige Wege an eine Container-Anwendung zu betreiben und zu skalieren. Deshalb kann in dieser Arbeit nicht auf alle eingegangen werden. Meist wird ein Container-Orchestrations-Tool verwendet, um das manuelle Verteilen der Container auf Computer-Clustern zu vermeiden. Bei Kubernetes gibt es den Horizontal Pod Autoscaler (HPA), der die automatische Skalierung von Pods in Abhängigkeit der CPU-Auslastung ermöglicht\cite{noauthor_horizontal_nodate-1}. Auch bei Nutzung des AWS Elastic Kubernetes Service (EKS) ist ein automatische Skalierung möglich\cite{noauthor_horizontal_nodate}. Auch die Nutzung eines Vertical Pod Autoscaler (VPA) ist möglich, der automatisch die Ressourcen einzelner Container skaliert\cite{noauthor_vertical_nodate}. Es kann auch ein Cluster Autoscaler verwendet werden, um zusätzlich zu der Anzahl der Container auch die Anzahl der Kubernetes-Knoten hoch zu skalieren\cite{noauthor_cluster_nodate}.
Auf die Performance-Tests all dieser Konfigurationen kann in dieser Arbeit unmöglich eingegangen werden, da es zu diesem Thema zu viele Möglichkeiten und auch Wege zur Optimierung gibt. Beispielsweise lässt sich die Schwelle der CPU-Auslastung einstellen, ab der die Anzahl der Container hoch- oder runter-skaliert werden soll. Liegt die Schwelle zu niedrig, skaliert das System evtl. zu früh und die Kosten steigen. Liegt die Schwelle zu hoch, skaliert das System evtl. zu spät und die Performanz sinkt.

In dieser Arbeit wurde AWS ECS mit dem Fargate-Starttyp verwendet, um die Einstellung eines Clusters nicht vornehmen zu müssen. Fargate verwaltet die Knoten des Clusters automatisch. Der ordinäre Weg der Cluster-Erstellung wäre es, mehrere Virtuelle Maschinen zu starten, zu konfigurieren und jede dem Cluster zuzuweisen. Durch die Nutzung von Fargate kann die Konfiguration von Container-Clustern also erheblich vereinfacht werden. ECS und Fargate bieten mit Auto-Scaling auch eine Möglichkeit der automatischen Skalierung an. Diese funktioniert zusammen mit AWS CloudWatch Alarmen. Dazu lässt sich eine von zwei verschiedenen Policies einstellen.

Bei einer Step Scaling Policy lassen sich, ähnlich wie bei Kubernetes HPA, Grenzen für die Skalierung auf Basis von CloudWatch Metriken, also bspw. CPU- oder Arbeitsspeicher-Auslastung, festlegen. CloudWatch überprüft dann in bestimmten Intervallen die Metriken und schlägt Alarm, wenn eine Metrik über oder unter dem spezifizierten Schwellwert liegt. Fargate reagiert auf den Alarm und skaliert die Anzahl der Container innerhalb des Clusters hoch oder herunter. 

Bei einer Target Tracking Policy, lässt sich für Metriken ein Ziel festlegen, das eingehalten werden soll. Beispielweise könnte man ein Ziel von 75\% CPU-Auslastung festlegen. Mithilfe der CloudWatch Alarme wird dann versucht, dieses Ziel möglichst einzuhalten. 

Problematisch ist allerdings die Größe des Intervalls, in dem die Metriken überprüft werden können. Standardmäßig kann dies nur alle fünf Minuten erfolgen. Träfe die Container-Anwendung eine plötzliche Spitzenlast, würde es fünf Minuten dauern, bis reagiert und die Kapazität erhöht werden könnte. Nach Absprache mit AWS kann sich dieses Intervall auf eine Minute senken lassen. Dies ist allerdings, verglichen mit den Skalierungsmöglichkeiten von AWS Lambda, noch immer zu langsam für Anwendungen die hochverfügbar sein müssen.

Wichtig für eine schnelle Skalierung ist vor allem auch die Größe des Containers. Da bei jeder neu hinzugefügten Container-Instanz das Container-Image von der Registry heruntergeladen werden muss, ist es notwendig, die Image-Größe möglichst zu minimieren. Zum Einsatz kommende Techniken sind hierbei beispielsweise die Nutzung eines Alpine-Images als Basis-Image, einer besonders kleinen Linux-Distribution, Multi-Stage Builds, mit denen unnötige Dateien entfernt werden können oder Layer-Merging, bei dem die Anzahl der Docker-Layer minimiert wird.
In Zukunft können also noch viele Aspekte des Skalierungsverhaltens und der Optimierung von Container-Anwendungen mit Performance Tests untersucht werden. 
Auch das Skalierungsverhalten von Lambda-Funktionen kann mit Autoscaling und provisionierter Nebenläufigkeit variiert werden. Lambda ist ein von Natur aus horizontal skalierendes System, daher müssen vom Entwickler theoretisch keine Einstellungen vorgenommen werden, um eine hochverfügbare Anwendung zu schaffen. Um auch Cold-Starts möglichst zu vermeiden, lässt sich die gewollte Nebenläufigkeit allerdings auch schon vor einem Benutzer-Ansturm definieren (Provisioned Concurrency). Lambda startet dann bereits Funktionen vor, die dann bei Bedarf keinen Kaltstart mehr erfordern, sondern direkt einen Warmstart durchführen können. Kombinieren lässt sich dies mit Autoscaling, um die provisionierte Kapazität an steigende Anfragezahlen anzupassen. 

Auch die Größe des Arbeitsspeicher einer Lambda-Funktion kann einen Einfluss auf das Skalierungsverhalten nehmen. Da eine Funktion mit größerem Speicher auch mehr CPU zugewiesen bekommt, können Anfragen, bei besonders CPU-intensiven Aufgaben, schneller verarbeitet werden und es werden eventuell weniger nebenläufige Funktionen und damit weniger Cold-Starts benötigt. Es gibt Tools wie "`AWS Lambda Power Tuning"'\cite{casalboni_alexcasalboniaws-lambda-power-tuning_2021}, die es für solche Funktionen ermöglichen, die beste Konfiguration zu finden.

Es gibt darüber hinaus vielfältige Wege, die Coldstart Zeit einer Lambda-Funktion zu verringern. Ähnlich zum Docker-Container, hat auch die Größe einer Lambda-Funktion Einfluss auf die Startzeit. Denn bei jedem Coldstart muss der Funktions-Code in den Lambda-Container geladen werden. Bei einigen Sprachen wie Java oder .NET macht ebenfalls die Konfiguration des Lambda-Arbeitsspeichers einen großen Unterschied\cite{malishev_aws_2019}. 

Immer häufiger werden auch Mischformen von Container und Serverless. Beispielsweise bietet AWS seit Ende 2020 an, Container über AWS Lambda verfügbar zu machen\cite{noauthor_aws_nodate-1}. Darüber könnten Container und FaaS-Angebote verschiedener Cloud-Anbieter verglichen werden, zum Beispiel von Microsoft Azure oder Google Cloud Platform.

Die in dieser Arbeit durchgeführten Tests waren auf eine einzige Beispielanwendung beschränkt. Es lassen sich aber für jede beliebige Anwendung Performance-Tests durchführen. In Zukunft könnte das für diese Arbeit genutzte Testing und Analyse-System daher ausgebaut werden, damit es für jede beliebige Anwendung nutzbar ist. Dies kann Organisationen dabei helfen, die Nutzung ihrer Technologien besser zu evaluieren. Es könnten ebenfalls noch weitere Metriken aus AWS CloudWatch, wie z.B. die tatsächlichen Funktions-Kosten, in die Analyse integriert werden und somit den Vergleich beider Technologien noch weiter verbessern. Auch andere Services wie AWS EKS oder Elastic Beanstalk könnten mit diesem System getestet werden.

