\section{Related Work}
Serverless ist allgemein ein noch junges Thema, das erst mit der Einführung von AWS Lambda im Jahre 2014 viel Aufmerksamkeit erfuhr. Es gibt bereits einige Studien zu der Performance von Serverless-Anwendungen, jedoch wurde in den meisten Studien nur Micro-Benchmarks betrachtet, d.h Tests, die nur einen Aspekt untersuchen, bspw. die CPU-Floating-Point Performance und keine realistischen Applikationen untersuchen\cite{scheuner_function-as--service_2020}. Vergleiche mit der Performance von Container-Anwendungen sind nur sehr wenige zu finden. 

McGrath und Brenner untersuchten die Performanz von Serverless-Funktionen durch mehrere verschiedene Tests. Unter anderem wurde ein Nebenläufigkeits-Test (concurrency test) vorgestellt, bei dem eine Funktion, die sofort terminiert, von einer linear ansteigenden Anzahl an Clients so oft wie möglich hintereinander aufgerufen. Gemessen wurde dabei die Anzahl der Antworten pro Sekunde (responses per second). Ziel dieses Tests war, die performante Ausführung einer skalierten Funktion zu messen. Das Ergebnis zeigte unterschiedliches Skalierverhalten für diverse Cloud-Anbieter; bei AWS Lambda wurde ein weitestgehend linearer Anstieg festgestellt. 
Des Weiteren werden für zukünftige Forschung noch andere die Performanz von Serverless-Funktionen beeinflussende Aspekte genannt, wie die Ausführung mehrerer Funktionen anstatt nur einer einzigen (single function execution), die Code-Größe einer Serverless-Funktion und unterschiedliche CPU-Allokation (in der Studie wurde lediglich 512MB RAM verwendet).

Hendrickson et al. verglichen in ihrer Arbeit die Performance von AWS Lambda mit der eines in AWS Beanstalk laufendem Docker-Containers\cite{hendrickson_serverless_2017}. Dazu sendeten die Forscher jeweils 100 RPC-Requests an beide Services, wobei jeder Service eine Laufzeit von 200ms beanspruchte. Die Durchführung des Tests ergab, dass die Antwortzeit bei Lambda mit einem Medianwert von 1,6 Sekunden deutlich vor der von Beanstalk mit bis zu 20 Sekunden liegt. Als Grund dafür wird angeführt, dass Lambda innerhalb von einigen Millisekunden 100 Instanzen auf die der Last verteilt wurde, während bei Beanstalk alle Anfragen von einer einzigen Instanz bearbeitet wurde, obwohl alle Einstellungen getroffen wurden, damit Beanstalk so schnell wie möglich hochskalieren kann. Hier zeigen sich deutlich die automatischen Skalierungsvorteile einer FaaS Applikation. Während es bei Beanstalk 20 verschiedene Einstellungsmöglichkeiten gäbe, übernimmt Lambda dies vollkommen automatisch.
Allerdings wird auch deutlich, dass die Latenz von Lambda Funktionen bei einer normalen Last deutlich über der eines Containers liegt. Mit der gleichen Testumgebung und unter leichter Last, performe Lambda 10 mal schlechter als Beanstalk. Da dieser Test im Jahre 2017 durchgeführt wurde, stimmen diese Ergebnisse aber vermutlich nicht mit den in der Zwischenzeit an Lambda vorgenommenen Performance-Verbesserungen überein.

Villamizar et al. verglichen die Performance und infrastrukturellen Kosten einer auf verschiedene Arten deployten Applikation\cite{villamizar_infrastructure_2016}. Die Anwendung wurde als Monolith und als Microservices mit und ohne AWS Lambda betrieben. Dabei zeigte sich,  dass die Kosten für den Betrieb bei einer auf Lambda basierten Microservices Architektur deutlich (mehr als 70 Prozent) geringer ausfallen können, als bei einem Monolith oder wenn die Microservices von den Entwicklern selbst gemanaged werden. Ebenfalls wurde die Performance der verschiedenen Ansätze mittels der Metrik der durchschnittlichen Antwortzeit (average response time - ART) verglichen. Es wurde deutlich, dass Lambda in unterschiedlichen Test-Szenarien nahezu die gleich ART beibehält, was auf dessen Skalierungsmöglichkeiten zurückgeführt wurde. Des Weiteren performte Lambda teilweise besser als die monolithische Architektur und deutlich besser als die selbst-gemanagten Microservices.

Verschiedene Server-Hosting Technologien, darunter auch AWS Lambda und AWS Fargate, wurden 2020 von Jain et al. auf ihre Performanz untersucht. Ähnlich zu dieser Arbeit wurde eine Notiz-Anwendung deployed, allerdings handelte es sich dabei um eine Frontend-Anwendung. Als Test-Metriken wurde sich demnach ausschließlich auf solche beschränkt, die das Rendering der Applikation im Web-Browser des Endbenutzer betreffen, bspw. die Page-Load-Time und Start-Render-Time. Dies steht im Gegensatz zu dieser Arbeit, bei dem ausschließlich Backends miteinander verglichen werden. Die Ergebnisse der Arbeit zeigten dennoch, dass ECS mit Fargate deutlich besser performte als AWS Lambda und sogar als ECS mit Elastic Compute Cloud (EC2). Es wurden jedoch weder Stress-Tests der Anwendungen durchgeführt, noch die Kostenunterschiede untersucht.

Alex DeBrie untersuchte 2019 in einem Artikel auf seiner Blog-Seite die Performance von ECS Fargate Containern und der von AWS Lambda\cite{debrie_aws_2019}. Dazu wurde ähnlich wie in dieser Arbeit ein HTTP-Endpunkt deployed und 15.000 Requests an jede Variante gesendet. Die HTTP Endpunkte sendeten dann den Payload des Requests an die Amazon Simple Notification Service (SNS) bevor die Antwort zurückgesendet wurde. Zur Auswertung wurden Percentile der Antwortzeit verwendet. Es zeigte sich, dass die Fargate Container den Lambda Funktionen deutlich in der Performance überlegen waren. Allerdings wurde nur eine einzige Konfiguration für beide Technologien getestet.

Nach der Betrachtung der Relevanten Arbeiten und Artikel zeigt sich also, dass es bisher noch keine Studie gibt, die die Performanz von Containern und Serverless-Funktionen anhand mehrerer Konfigurationen und mit verschiedenen Performance-Tests evaluiert. Diese Lücke versucht die vorliegende Arbeit zu schließen, indem reproduzierbare Test mit verschiedenen Konfigurationen durchgeführt werden und auch auf die Kosten der beiden Technologien eingegangen wird.